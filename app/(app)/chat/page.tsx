"use client";
import React from "react";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";
import { Mic, Send, Square, Volume2, VolumeX } from "lucide-react";
import { createRecognition, getSpeechSupport, speak, stopSpeaking } from "@/lib/voice";
import { useVoice } from "@/lib/state/voice-context";
import { getSelectedJob } from "@/lib/state/profile";
import { ttsPlayer } from "./ttsPlayer";

// ì§ë¬´ë³„ ë©´ì ‘ê´€ ì´ë¯¸ì§€ ë§¤í•‘
const interviewImageMap: Record<string, string> = {
  "office-support": "/images/man_interviewer.png",
  "assembly-packaging": "/images/interviewer_manufacture.png",
  "customer-service": "/images/interviewer_service.png",
  "environment-cleaning": "/images/interviewer_cleaning.png",
  "care-support": "/images/interviewer_support.png",
  "logistics": "/images/interviewer_trainsportation.png",
};

// ì§ë¬´ë³„ ì´ë¯¸ì§€ í¬ì»¤ìŠ¤ ìœ„ì¹˜ (ì–¼êµ´ì´ ìœ„ìª½ì— ë³´ì´ë„ë¡ ì¡°ì •)
const imagePositionMap: Record<string, string> = {
  "care-support": "center 20%",
  "customer-service": "center 25%",
  "assembly-packaging": "center 20%",
  // ë‚˜ë¨¸ì§€ ì§ë¬´ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
};

// ì§ë¬´ IDì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°˜í™˜ (fallback: office-support)
function getInterviewerImage(jobId: string | null): string {
  if (!jobId) {
    return interviewImageMap["office-support"]!;
  }
  return interviewImageMap[jobId] ?? interviewImageMap["office-support"]!;
}

// ì§ë¬´ IDì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ í¬ì»¤ìŠ¤ ìœ„ì¹˜ë¥¼ ë°˜í™˜
function getImagePosition(jobId: string | null): string {
  if (!jobId) {
    return "center 150px";
  }
  return imagePositionMap[jobId] ?? "center 150px";
}

export default function ChatPage() {
  const [started, setStarted] = React.useState(false);
  const [userDraftAnswer, setUserDraftAnswer] = React.useState("");
  const [listening, setListening] = React.useState(false);
  const [loading, setLoading] = React.useState(false);
  
  // ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ (OpenAI messages í˜•ì‹)
  const [messages, setMessages] = React.useState<Array<{ role: "system" | "user" | "assistant"; content: string }>>([]);
  
  // Live interview state - only current messages
  const [currentInterviewerMessage, setCurrentInterviewerMessage] = React.useState("");
  const [currentUserMessage, setCurrentUserMessage] = React.useState("");
  
  // Display states for typing animation
  const [displayInterviewerText, setDisplayInterviewerText] = React.useState("");
  const [displayUserText, setDisplayUserText] = React.useState("");
  
  // Selected job info
  const [selectedJobId, setSelectedJobId] = React.useState<string | null>(null);
  
  const support = getSpeechSupport();
  const { screenReaderEnabled, interviewVoiceEnabled, setInterviewVoiceEnabled } = useVoice();
  const typingIntervalRef = React.useRef<NodeJS.Timeout | null>(null);
  const userTypingIntervalRef = React.useRef<NodeJS.Timeout | null>(null);
  const inputRef = React.useRef<HTMLTextAreaElement | null>(null);
  const hasReadGuideRef = React.useRef<boolean>(false);
  
  // TTS í”Œë ˆì´ì–´ ìƒíƒœ
  const [ttsState, setTtsState] = React.useState(ttsPlayer.getState());

  // í™”ë©´ì„¤ëª… ì•ˆë‚´ ë¬¸êµ¬
  const guideText = "ë©´ì ‘ ì‹œì‘ ë²„íŠ¼ì„ ëˆ„ë¥´ì‹œë©´ ë©´ì ‘ê´€ê³¼ì˜ ëŒ€í™”ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.";

  // í™”ë©´ì„¤ëª… ì•ˆë‚´ ë¬¸êµ¬ ì½ê¸° (ë©´ì ‘ íƒ­ ì§„ì… ì‹œ ë˜ëŠ” í™”ë©´ì„¤ëª… ONìœ¼ë¡œ ì „í™˜ ì‹œ)
  React.useEffect(() => {
    if (screenReaderEnabled && !hasReadGuideRef.current) {
      stopSpeaking();
      speak(guideText, { lang: "ko-KR" });
      hasReadGuideRef.current = true;
    }
    return () => {
      if (!screenReaderEnabled) {
        hasReadGuideRef.current = false;
      }
    };
  }, [screenReaderEnabled]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë¦¬ì…‹
  React.useEffect(() => {
    return () => {
      hasReadGuideRef.current = false;
      stopSpeaking();
    };
  }, []);

  // Load selected job info
  React.useEffect(() => {
    async function loadSelectedJob() {
      const jobId = await getSelectedJob();
      console.log('[ChatPage] Loaded jobId:', jobId);
      setSelectedJobId(jobId);
    }
    loadSelectedJob();
  }, []);

  // TTS í”Œë ˆì´ì–´ ìƒíƒœ êµ¬ë…
  React.useEffect(() => {
    const unsubscribe = ttsPlayer.subscribe(() => {
      setTtsState(ttsPlayer.getState());
    });
    return unsubscribe;
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ TTS ì •ë¦¬
  React.useEffect(() => {
    return () => {
      ttsPlayer.stop();
    };
  }, []);



  // Cleanup intervals on unmount
  React.useEffect(() => {
    return () => {
      if (typingIntervalRef.current) {
        clearInterval(typingIntervalRef.current);
      }
      if (userTypingIntervalRef.current) {
        clearInterval(userTypingIntervalRef.current);
      }
    };
  }, []);


  // Typing animation helper
  const animateText = (fullText: string, setFn: (text: string) => void, speed = 30) => {
    setFn("");
    let i = 0;
    const interval = setInterval(() => {
      i++;
      setFn(fullText.slice(0, i));
      if (i >= fullText.length) clearInterval(interval);
    }, speed);
  };

  // Show interviewer message with typing animation
  const showInterviewerMessage = (fullText: string) => {
    setCurrentInterviewerMessage(fullText);
    animateText(fullText, setDisplayInterviewerText);
  };

  // Show user message with typing animation
  const showUserMessage = (fullText: string) => {
    setCurrentUserMessage(fullText);
    animateText(fullText, setDisplayUserText);
  };

  async function startInterview() {
    setStarted(true);
    const initialMessage = "ì•ˆë…•í•˜ì„¸ìš”. ë©´ì ‘ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ë‹¤ë©´ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.";
    
    // Clear any previous messages and show only current interviewer message
    setCurrentUserMessage("");
    setCurrentInterviewerMessage("");
    
    // messages íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ë° ì²« assistant ë©”ì‹œì§€ ì¶”ê°€ (ì›°ì»´ë©”ì‹œì§€)
    setMessages([
      { role: "assistant", content: initialMessage }
    ]);
    
    // Show message immediately and TTS
    showInterviewerMessage(initialMessage);
    playInterviewTTS(initialMessage);
    window.scrollTo({ top: 0, behavior: "smooth" });
  }

  async function sendMessage(text: string) {
    if (!text.trim() || loading) return; // request de-duplication: ì´ë¯¸ ìš”ì²­ ì¤‘ì´ë©´ ë¬´ì‹œ
    
    // Clear previous user message only when starting new response
    setCurrentUserMessage("");
    
    // Show user's current response immediately
    showUserMessage(text);
    
    // Clear input but keep user message visible
    setUserDraftAnswer("");
    
    // Set loading state (request de-duplication)
    setLoading(true);

    // messages íˆìŠ¤í† ë¦¬ì— user ë©”ì‹œì§€ ì¶”ê°€
    const userMessage = { role: "user" as const, content: text };
    const updatedMessages = [...messages, userMessage];
    setMessages(updatedMessages);

    // ë¡œê¹…: ìš”ì²­ ì „ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í™•ì¸
    console.log("[ChatPage] Sending message, history length:", updatedMessages.length);
    if (updatedMessages.length >= 2) {
      const lastTwo = updatedMessages.slice(-2);
      console.log("[ChatPage] Last 2 messages:", lastTwo.map(m => ({ role: m.role, contentLength: m.content.length })));
    }

    try {
      const res = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ 
          messages: updatedMessages,
          jobId: selectedJobId 
        }),
      });
      
      if (!res.ok) {
        throw new Error("API ìš”ì²­ ì‹¤íŒ¨");
      }
      
      if (!res.body) {
        throw new Error("ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
      }
      
      const reader = res.body.getReader();
      const decoder = new TextDecoder("utf-8", { fatal: false });
      let assistant = "";
      
      while (true) {
        const { value, done } = await reader.read();
        if (done) break;
        
        // UTF-8 ì•ˆì „ ë””ì½”ë”© (ë©€í‹°ë°”ì´íŠ¸ ë¬¸ì ë³´í˜¸)
        const chunk = decoder.decode(value, { stream: true });
        assistant += chunk;
      }
      
      // ìµœì¢… ë””ì½”ë”© ì™„ë£Œ (ë‚¨ì€ ë²„í¼ ì²˜ë¦¬)
      const finalChunk = decoder.decode();
      if (finalChunk) {
        assistant += finalChunk;
      }
      
      // í™”ë©´ í‘œì‹œìš© í…ìŠ¤íŠ¸ (ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
      const displayText = assistant.trim();
      // TTSìš© í…ìŠ¤íŠ¸ (í™”ë©´ê³¼ ë™ì¼, í•„ìš”ì‹œ ë³„ë„ ì „ì²˜ë¦¬ ê°€ëŠ¥)
      const ttsText = displayText;
      
      // ë™ì¼ ì‘ë‹µ ë°˜ë³µ ë°©ì§€: ë§ˆì§€ë§‰ assistant ë©”ì‹œì§€ì™€ ë™ì¼í•˜ë©´ ì¬ìƒì„± ìš”ì²­
      const lastAssistantMessage = updatedMessages.filter(m => m.role === "assistant").pop();
      if (lastAssistantMessage && lastAssistantMessage.content === displayText) {
        console.warn("[ChatPage] Duplicate response detected, forcing regeneration");
        // ì—ëŸ¬ ë©”ì‹œì§€ ëŒ€ì‹  ë‹¤ë¥¸ ì§ˆë¬¸ ìš”ì²­
        const fallbackMessage = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì§€ì› ë™ê¸°ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?";
        const assistantMessage = { role: "assistant" as const, content: fallbackMessage };
        setMessages([...updatedMessages, assistantMessage]);
        showInterviewerMessage(fallbackMessage);
        playInterviewTTS(fallbackMessage);
        setLoading(false);
        return;
      }
      
      // ë””ë²„ê¹…: API ì‘ë‹µ í™•ì¸ (í”„ë¡œë•ì…˜ì—ì„œë„ ê¸¸ì´ í™•ì¸ ê°€ëŠ¥)
      console.log("[ChatPage] API Response received, length:", displayText.length);
      console.log("[ChatPage] Messages history length before append:", updatedMessages.length);
      if (process.env.NODE_ENV !== "production") {
        console.log("[ChatPage] API Response preview:", displayText.substring(0, 150) + (displayText.length > 150 ? "..." : ""));
      }
      
      // messages íˆìŠ¤í† ë¦¬ì— assistant ì‘ë‹µ ì¶”ê°€
      const assistantMessage = { role: "assistant" as const, content: displayText };
      setMessages([...updatedMessages, assistantMessage]);
      
      // Show new interviewer message immediately (í™”ë©´ í‘œì‹œìš© - ì›ë³¸ í…ìŠ¤íŠ¸)
      showInterviewerMessage(displayText);
      // TTS ì¬ìƒ (ë³„ë„ í…ìŠ¤íŠ¸ ì‚¬ìš©)
      playInterviewTTS(ttsText);
      
    } catch (e) {
      console.error("Send message error:", e);
      const errorMessage = "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.";
      showInterviewerMessage(errorMessage);
      playInterviewTTS(errorMessage);
      // ì—ëŸ¬ ë°œìƒ ì‹œ messages íˆìŠ¤í† ë¦¬ì—ì„œ ë§ˆì§€ë§‰ user ë©”ì‹œì§€ ì œê±° (ë¡¤ë°±)
      setMessages(messages);
    } finally {
      // CRITICAL: Always re-enable input
      setLoading(false);
    }
  }

  function handleRecognizeToggle() {
    if (!support.sttSupported) return;
    if (listening) {
      (window as any)._recognition?.stop();
      setListening(false);
      return;
    }
    const recognition = createRecognition("ko-KR");
    if (!recognition) return;
    (window as any)._recognition = recognition;
    recognition.onresult = (event: any) => {
      // ìµœì¢… ì¸ì‹ë§Œ ì…ë ¥ì°½ì— ë°˜ì˜í•˜ì—¬ ì¤‘ë³µ ëˆ„ì ì„ ë§‰ëŠ”ë‹¤
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const res = event.results[i];
        if (!res.isFinal) continue;
        const transcript = res[0].transcript.trim();
        if (transcript) {
          setUserDraftAnswer((prev) => (prev ? prev + " " : "") + transcript);
        }
      }
    };
    recognition.onend = () => setListening(false);
    recognition.start();
    setListening(true);
  }

  function handleSubmit() {
    if (!userDraftAnswer.trim() || loading) return; // request de-duplication
    sendMessage(userDraftAnswer);
  }

  // Handle key down events for text input (request de-duplication)
  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      if (userDraftAnswer.trim() && !loading) { // request de-duplication
        sendMessage(userDraftAnswer.trim());
      }
    }
  };

  // Interviewer TTS function (OpenAI TTS ì‚¬ìš©)
  function playInterviewTTS(messageText: string) {
    if (interviewVoiceEnabled) {
      ttsPlayer.enqueue(messageText, selectedJobId);
    }
  }

  // ì„ íƒëœ ì§ë¬´ì— ë”°ë¥¸ ë©´ì ‘ê´€ ì´ë¯¸ì§€ ê²½ë¡œ ë° í¬ì»¤ìŠ¤ ìœ„ì¹˜
  const interviewerImage = getInterviewerImage(selectedJobId);
  const imagePosition = getImagePosition(selectedJobId);
  
  // ë””ë²„ê¹…: jobIdì™€ ì´ë¯¸ì§€ ê²½ë¡œ ë¡œê·¸
  React.useEffect(() => {
    console.log('[ChatPage] selectedJobId:', selectedJobId, '-> image:', interviewerImage, '-> position:', imagePosition);
  }, [selectedJobId, interviewerImage, imagePosition]);

  return (
    <div 
      key={selectedJobId || 'default'} // jobId ë³€ê²½ ì‹œ ê°•ì œ ë¦¬ë Œë”ë§
      className="h-screen w-screen relative overflow-hidden"
      style={{
        backgroundImage: `url("${interviewerImage}")`,
        backgroundSize: 'contain',
        backgroundPosition: imagePosition,
        backgroundRepeat: 'no-repeat',
        position: 'fixed',
        top: 0,
        left: 0,
        right: 0,
        bottom: 0
      }}
    >
      {/* Top white overlay to prevent menu overlap */}
      <div className="absolute top-0 left-0 right-0 h-20 bg-white z-50"></div>
      
      {/* ë©´ì ‘ ìŒì„± í† ê¸€ ë²„íŠ¼ */}
      <div className="absolute top-4 right-4 z-50 flex items-center gap-2">
        <Button
          aria-label={interviewVoiceEnabled ? "ìŒì„± ë„ê¸°" : "ìŒì„± ì¼œê¸°"}
          variant="outline"
          size="sm"
          onClick={() => setInterviewVoiceEnabled(!interviewVoiceEnabled)}
          className="bg-white/90 backdrop-blur"
        >
          {interviewVoiceEnabled ? <Volume2 className="h-4 w-4" /> : <VolumeX className="h-4 w-4" />}
          <span className="ml-2 hidden sm:inline">{interviewVoiceEnabled ? "ìŒì„± ON" : "ìŒì„± OFF"}</span>
        </Button>
      </div>

      {/* TTS ìƒíƒœ í‘œì‹œ */}
      {interviewVoiceEnabled && (ttsState.isSpeaking || ttsState.queueLength > 0) && (
        <div className="absolute top-16 right-4 z-50 bg-white/90 backdrop-blur rounded-lg px-3 py-2 shadow-lg flex items-center gap-2">
          <Volume2 className="h-4 w-4 text-blue-600 animate-pulse" />
          <span className="text-sm text-slate-700">
            {ttsState.isSpeaking ? "ğŸ”Š ì¬ìƒ ì¤‘..." : `ëŒ€ê¸° ì¤‘ (${ttsState.queueLength})`}
          </span>
        </div>
      )}
      
      {/* Interviewer area - fixed at top */}
      <div className="relative z-10 pt-8 pb-24">
        <div className="mx-auto max-w-4xl px-4">
          {!started ? (
            <div className="flex flex-col items-center justify-center min-h-[50vh]">
              <Button 
                onClick={startInterview} 
                aria-label="ë©´ì ‘ ì‹œì‘"
                className="bg-white text-black hover:bg-gray-100 text-3xl px-12 py-6 rounded-xl shadow-2xl border-4 border-gray-400 font-bold"
                size="lg"
                style={{
                  filter: 'none',
                  opacity: 1,
                  zIndex: 100
                }}
              >
                ë©´ì ‘ ì‹œì‘
              </Button>
            </div>
          ) : (
            <>
              {/* Current interviewer message - floating speech bubble */}
              {currentInterviewerMessage && (
                <div className="flex justify-center mb-8 px-4" style={{marginTop: '100px'}}>
                  <div className="bg-slate-100 rounded-2xl px-6 py-4 shadow-[0_12px_24px_rgba(0,0,0,0.08)] max-w-[800px] w-full mx-auto animate-fadeIn">
                    <p className="text-xl leading-relaxed text-slate-800 whitespace-pre-wrap">
                      {displayInterviewerText}
                    </p>
                  </div>
                </div>
              )}

              {/* Loading state */}
              {loading && !currentInterviewerMessage && (
                <div className="flex justify-center mb-8 px-4" style={{marginTop: '100px'}}>
                  <div className="bg-white/90 backdrop-blur rounded-2xl px-6 py-4 shadow-lg">
                    <p className="text-xl leading-relaxed text-slate-800">
                      ë©´ì ‘ê´€ì´ ì§ˆë¬¸ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...
                    </p>
                  </div>
                </div>
              )}
            </>
          )}
        </div>
      </div>

      {/* Current user response - blue bubble positioned above input bar */}
      {started && currentUserMessage && (
        <div
          className="
            fixed
            inset-x-0
            flex
            justify-center
            px-6
            z-40
          "
          style={{
            bottom: "160px", // adjusted to be just above input with small margin
          }}
        >
          <div className="
            bg-[#377cfb]
            text-white
            rounded-t-2xl
            rounded-b-xl
            px-6
            py-4
            shadow-[0_8px_20px_rgba(0,0,0,0.12)]
            w-full
            max-w-[800px]
            mx-auto
            animate-fadeIn
          ">
            <p className="text-xl leading-relaxed whitespace-pre-wrap">
              {displayUserText}
            </p>
          </div>
        </div>
      )}



      {/* Bottom fixed user input area */}
      {started && (
        <div className="fixed inset-x-0 bottom-0 bg-white p-4 z-50 shadow-[0_-4px_12px_rgba(0,0,0,0.08)]">
          <div className="mx-auto max-w-4xl">
            
            {/* Answer input area with microphone button inside */}
            <div className="relative">
              <Textarea
                value={userDraftAnswer}
                onChange={(e) => setUserDraftAnswer(e.target.value)}
                placeholder="ë°©ê¸ˆ í•œ ë§ì„ í™•ì¸í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”..."
                className="min-h-[100px] max-h-40 resize-none pr-28 pl-20 bg-gray-100 border-2 border-gray-300 rounded-xl shadow-lg text-xl placeholder:text-xl focus:border-blue-500 focus:bg-white"
                rows={3}
              />
              
              {/* Microphone button inside textarea */}
              <Button
                onClick={handleRecognizeToggle}
                className={`absolute left-2 top-2 h-16 w-16 rounded-full ${
                  listening 
                    ? "bg-red-500 text-white hover:bg-red-600" 
                    : "bg-purple-200 text-purple-700 hover:bg-purple-300"
                }`}
                aria-pressed={listening}
                aria-label={listening ? "ìŒì„± ì…ë ¥ ì¤‘ì§€" : "ìŒì„± ì…ë ¥ ì‹œì‘"}
              >
                {listening ? <Square className="h-8 w-8" /> : <Mic className="h-8 w-8" />}
              </Button>
              
              {/* Submit button */}
              <Button
                onClick={handleSubmit}
                disabled={!userDraftAnswer.trim()}
                size="icon"
                className="absolute right-2 bottom-2 h-12 w-12 bg-blue-500 hover:bg-blue-600 disabled:opacity-50"
                aria-label="ë‹µë³€ ì „ì†¡"
              >
                <Send className="h-6 w-6" />
              </Button>
              
            </div>
          </div>
        </div>
      )}
    </div>
  );
}


